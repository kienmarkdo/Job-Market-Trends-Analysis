{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grk4Upln2TS6"
   },
   "source": [
    "# Data Staging\n",
    "Extract, Transform, Load (ETL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGF4H4Y6_PkM"
   },
   "source": [
    "## Extract datasets into dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyXhWE0Q_Xk9"
   },
   "source": [
    "Extract job posting information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5VYvry0jfKSM",
    "outputId": "c1e668bb-2cd6-4810-da2c-18d529800388"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('job_descriptions.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdjTFL6H_fhj"
   },
   "source": [
    "Extract City Population information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "DNrSb3mQ_jJ1",
    "outputId": "067bbdb9-884b-479f-d58f-a740482917cf"
   },
   "outputs": [],
   "source": [
    "df_population = pd.read_csv('CityPopulation.csv')\n",
    "df_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQfIXkWe8-0b"
   },
   "source": [
    "Extract company headquarters country location and company size (number of employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8l934sXT8-fI",
    "outputId": "c0637aa8-a9a1-4ff1-d5fe-9b5220c0763f"
   },
   "outputs": [],
   "source": [
    "df_company = pd.read_csv('CompanyInformation.csv')\n",
    "df_company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7pS8YpilY7u"
   },
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2qDI-s8SJTA"
   },
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = True #https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbtKuIATlNat",
    "outputId": "9ebcf765-9717-4723-d97f-ff5ddaa7bbf4"
   },
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUFMXsoboFWV"
   },
   "source": [
    "Keep only the countries we want for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYx1giDKoC2c"
   },
   "outputs": [],
   "source": [
    "# Define the values to keep in the \"Country\" column\n",
    "desired_countries = ['USA', 'UK', 'Canada', 'France', 'Japan', 'Belgium', 'Australia', 'Spain', 'India', 'Germany', 'Singapore', 'Thailand', 'China', 'Portugal', 'Vietnam', 'Mauritius']\n",
    "\n",
    "# Filter the DataFrame to keep only rows with desired countries\n",
    "df = df[df['Country'].isin(desired_countries)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4VilwGnqwQ1"
   },
   "source": [
    "Drop unrequired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vADHw_HkppFN",
    "outputId": "25231966-f3cb-49ab-d94a-485fa0b88bf5"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['latitude', 'longitude', 'Contact Person', 'Contact', 'Job Description', 'Company Size'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg0VtRvrrrsV"
   },
   "source": [
    "Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Obg7ODXfrtXe"
   },
   "outputs": [],
   "source": [
    "# Columns to rename in df\n",
    "columns_to_rename = {\n",
    "    'skills':'Skills',\n",
    "    'location': 'City',\n",
    "    'Preference': 'Gender Preference',\n",
    "    'Role': 'Specialization',\n",
    "}\n",
    "\n",
    "df = df.rename(columns_to_rename, axis='columns')\n",
    "\n",
    "# columns to rename in df_population\n",
    "df_population.rename(columns={'City Population': 'Job City Population'}, inplace=True)\n",
    "\n",
    "# column to rename in df_company\n",
    "df_company.rename(columns={'Country': 'Company HQ Country'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVMrv1jbcRKp"
   },
   "source": [
    "Processing date values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qnk6z5l-IdyO",
    "outputId": "b95a03d3-1c2b-4eec-dae8-9e54bb67df42"
   },
   "outputs": [],
   "source": [
    "# convert date object to datetime\n",
    "df['Job Posting Date'] = pd.to_datetime(df['Job Posting Date'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JrHBwaUlJBx3"
   },
   "outputs": [],
   "source": [
    "# Extract the month and year from job posting date and add them to 2 separate columns\n",
    "df['Day'] = df['Job Posting Date'].dt.day # extract day\n",
    "df['Month'] = df['Job Posting Date'].dt.month # extract month\n",
    "df['Year'] = df['Job Posting Date'].dt.year # extract year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3njB16vLcUE1"
   },
   "source": [
    "Processing Salary Range and Years of Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCs8YCJ4M2I5"
   },
   "outputs": [],
   "source": [
    "# Split salary range in to minimum salary and maximum salary\n",
    "df[['Minimum Salary', 'Maximum Salary']] = df['Salary Range'].str.split('-', expand=True)\n",
    "\n",
    "# Keep only integers, using a regex, replace every non digit character by a \"\"\n",
    "df['Minimum Salary'] = df['Minimum Salary'].str.replace('[^\\d]', '', regex=True).astype(int)\n",
    "df['Maximum Salary'] = df['Maximum Salary'].str.replace('[^\\d]', '', regex=True).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fBvPERcV1qe"
   },
   "outputs": [],
   "source": [
    "# Transform salary into $ instead of in thousands unit\n",
    "df['Minimum Salary'] *= 1000\n",
    "df['Maximum Salary'] *= 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzzgdOwvU_iX"
   },
   "outputs": [],
   "source": [
    "# Split Years of experience range in to minimum experience and maximum experience\n",
    "df[['Minimum Experience (years)', 'Maximum Experience (years)']] = df['Experience'].str.split('to', expand=True)\n",
    "\n",
    "# Keep only integers, using a regex, replace every non digit character by a \"\"\n",
    "df['Minimum Experience (years)'] = df['Minimum Experience (years)'].str.replace('[^\\d]', '', regex=True).astype(int)\n",
    "df['Maximum Experience (years)'] = df['Maximum Experience (years)'].str.replace('[^\\d]', '', regex=True).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MGR3gY4oPSAb",
    "outputId": "ad297eab-21ef-4e5c-9018-d064dca551c3"
   },
   "outputs": [],
   "source": [
    "# Drop unneeded columns\n",
    "df = df.drop(columns=['Experience', 'Salary Range', 'Job Posting Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfLEBkkmcfKG"
   },
   "source": [
    "Handling null values within company profile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lp3dk47L7lFt",
    "outputId": "061399f3-142c-4563-b85a-1e8d518c87e0"
   },
   "outputs": [],
   "source": [
    "# Check if there are null values, no null values if we successfully added missing companies\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSw2fMbT483i",
    "outputId": "9b4af282-5492-4f30-fbb9-21c197a175ce"
   },
   "outputs": [],
   "source": [
    "# Checking which company has missing information on company profile\n",
    "null_company_profile_rows = df[df['Company Profile'].isnull() | (df['Company Profile'] == '')]\n",
    "\n",
    "# Extract unique companies from these rows\n",
    "unique_companies_with_null_profile = null_company_profile_rows['Company'].unique()\n",
    "\n",
    "print(unique_companies_with_null_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3deu1MF_5tZ9"
   },
   "outputs": [],
   "source": [
    "# handling missing values for company profile\n",
    "import json\n",
    "value_mapping = {\n",
    "    'Est√©e Lauder': {\"Sector\":\"Consumer Goods\",\"Industry\":\"Consumer Goods\",\"City\":\"New York\",\"State\":\"New York\",\"Zip\":\"10001\",\"Website\":\"www.elcompanies.com\",\"Ticker\":\"EL\",\"CEO\":\"Fabrizio Freda\"},\n",
    "    'Dunkin\\'Brands Group, Inc.': {\"Sector\":\"Restaurants\",\"Industry\":\"Food Services\",\"City\":\"Canton\",\"State\":\"Massachusetts\",\"Zip\":\"02021\",\"Website\":\"www.dunkindonuts.com\",\"Ticker\":\"DNKN\",\"CEO\":\"Nigel Travis\"},\n",
    "    'Peter Kiewit Sons': {\"Sector\":\"Construction/Infrastructure\",\"Industry\":\"Construction/Infrastructure\",\"City\":\"Omaha\",\"State\":\"Nebraska\",\"Zip\":\"68102\",\"Website\":\"www.kiewit.com\",\"Ticker\":\"N/A\",\"CEO\":\"Rick Lanoha\"},\n",
    "}\n",
    "\n",
    "# Filling in missing information for company profile\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row['Company Profile']):\n",
    "        company = row['Company']\n",
    "        if company in value_mapping:\n",
    "          company_profile_str = json.dumps(value_mapping[company])\n",
    "          df.at[index, 'Company Profile'] = company_profile_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdZDZ7h3xUKo",
    "outputId": "924f33e8-45f1-4d0f-abf4-8d5ab8c66156"
   },
   "outputs": [],
   "source": [
    "# Checking if missing data was filled in properly\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJlYVT63BdW-"
   },
   "source": [
    "Cleaning data for Company Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23Q7_SnQTL3D"
   },
   "outputs": [],
   "source": [
    "# Cleaning data that is formatted incorrectly in Company Profile\n",
    "rows_to_replace = df[df['Company'] == 'Quanta Services']\n",
    "df.loc[rows_to_replace.index, 'Company Profile'] = df.loc[rows_to_replace.index, 'Company Profile'].str.replace('\"Duke\" Austin', 'Austin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Th2wcAc6BsD0"
   },
   "source": [
    "Processing the Company Profile column\n",
    "\n",
    "Format for Company Profile is a dictionnary, and we want to have a column for each key of the dictionnary and fill the column with the value associated to the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s6o-yoAm_-bL",
    "outputId": "03632b94-7dc5-48a9-e111-ed29af739160"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_and_rename(dictionary_str, key, new_key):\n",
    "    try:\n",
    "        dictionary = ast.literal_eval(dictionary_str)\n",
    "        value = dictionary.get(key, None)\n",
    "        return value if value is not None else None\n",
    "    except (SyntaxError, ValueError):\n",
    "        return None\n",
    "\n",
    "# Define keys to extract and their column names\n",
    "key_to_new_key_mapping = {\n",
    "    'Sector': 'Company Sector',\n",
    "    'Industry': 'Company Industry',\n",
    "    'City': 'Company HQ City',\n",
    "    'Ticker': 'Company Ticker'\n",
    "}\n",
    "\n",
    "# Create new columns and fill with values\n",
    "for key, new_key in key_to_new_key_mapping.items():\n",
    "    df[new_key] = df['Company Profile'].apply(lambda x: extract_and_rename(x, key, new_key))\n",
    "\n",
    "# Drop the original Company Profile column\n",
    "df.drop(columns=['Company Profile'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhEEIiyS3mXv"
   },
   "source": [
    "Cleaning the Company HQ City column\n",
    "\n",
    "We noticed that some values for the City key included the city inside of it, so for example we have \"City\": \"London, UK\", but we only want the London part in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jiqezXw55kDP"
   },
   "outputs": [],
   "source": [
    "# We split at the comma\n",
    "split_cities = df['Company HQ City'].str.split(',')\n",
    "\n",
    "# Filtering elements with length 2\n",
    "split_cities_with_length_2 = split_cities[split_cities.apply(lambda x: len(x) == 2)]\n",
    "\n",
    "# Getting indices of rows with split cities of length 2\n",
    "indices_with_length_2 = split_cities_with_length_2.index\n",
    "\n",
    "# Replacing the existing values with only the first element of the split list\n",
    "df.loc[indices_with_length_2, 'Company HQ City'] = split_cities_with_length_2.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwPBQqpP5Xg5",
    "outputId": "c59857a5-6b1e-49e5-83bf-ca935d402d3b"
   },
   "outputs": [],
   "source": [
    "# Checking if there are still rows with the format where we have the country, if the output returns nothing, then we cleaned properly\n",
    "\n",
    "# Splitting the content of the 'Company HQ City' column at the comma\n",
    "split_cities = df['Company HQ City'].str.split(',')\n",
    "\n",
    "# Filtering elements with length 2\n",
    "split_cities_with_length_2 = split_cities[split_cities.apply(lambda x: len(x) == 2)]\n",
    "\n",
    "# Displaying the split content with elements of length 2\n",
    "print(split_cities_with_length_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHinM7nWB90e"
   },
   "source": [
    "Processing the Benefits values\n",
    "\n",
    "Format of Benefits table is {'Retirement Plans', 'Parental Leave', etc} and we want to have a column for each benefit and if the benefit is in the Object, we have True, and if it's not there we have False. So with the Object given above, Retirement Plans and Parental Leave will have True in their column and the others will have False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Rnm9ywAA2GAj",
    "outputId": "b58c0185-c801-4728-f774-7c7784870005"
   },
   "outputs": [],
   "source": [
    "benefit_columns = ['Retirement Plans','Stock Options or Equity Grants','Parental Leave','Paid Time Off (PTO)',\n",
    "                   'Flexible Work Arrangements','Health Insurance','Life and Disability Insurance',\n",
    "                   'Employee Assistance Program','Health and Wellness Facilities','Employee Referral Program',\n",
    "                   'Transportation Benefits','Bonuses and Incentive Programs']\n",
    "\n",
    "# Initialize all columns with False\n",
    "for column in benefit_columns:\n",
    "    df[column] = False\n",
    "\n",
    "# Function to set boolean values\n",
    "def set_benefit_values(row):\n",
    "    benefits = row['Benefits']\n",
    "    for column in benefit_columns:\n",
    "        if column in benefits:\n",
    "            row[column] = True\n",
    "    return row\n",
    "\n",
    "# Apply function to each row\n",
    "df = df.apply(set_benefit_values, axis=1)\n",
    "\n",
    "# Drop the original Benefits column\n",
    "df.drop(columns=['Benefits'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BC71EAGBF4du",
    "outputId": "64ac30a3-4c76-4cd6-af58-98f9d2387032"
   },
   "outputs": [],
   "source": [
    "# Checking if we have null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9r4Nl-HUuwU"
   },
   "source": [
    "Processing \"N/A\" values in Company Ticker column and replacing it with empty string. Only a small percentage of our data has a null value for this column, since this is a very small percentage, we ignore those missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IrIi3sbIXTpH"
   },
   "outputs": [],
   "source": [
    "df['Company Ticker'] = df['Company Ticker'].replace('N/A', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWgaxY_R2z9U"
   },
   "source": [
    "Cleaning strings in Company HQ City column that have special characters and aren't being displayed. This is happening for German cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Ri9BPVk5X2X"
   },
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'G ttingen': 'G√∂ttingen',\n",
    "    'Bad Homburg vor der H he': 'Bad Homburg vor der H√∂he',\n",
    "    'Unterf hring': 'Unterf√∂hring',\n",
    "    'Unterschlei heim': 'Unterschlei√üheim',\n",
    "    'D sseldorf': 'D√ºsseldorf'\n",
    "}\n",
    "\n",
    "# Perform replacements\n",
    "df['Company HQ City'] = df['Company HQ City'].replace(replacements, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWgaxY_R2z9U"
   },
   "source": [
    "Create a column to represent Quarter attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'Quarter' column based on 'Month'\n",
    "df['Quarter'] = df['Month'].apply(lambda x: (x - 1) // 3 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fp21GxpyxWAV"
   },
   "source": [
    "### Dataset Integrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNPkOzL2tCmU"
   },
   "source": [
    "We integrate our 3 datasets together: job_descriptions.csv, CityPopulation.csv and CompanyInformation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2oEIa0a3pNE"
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_population, how='left', on=[\"City\", \"Country\"])\n",
    "df = pd.merge(df, df_company, how='left', on=[\"Company\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "id": "Vkn1CR6IX4BU",
    "outputId": "062b4723-b797-4fcb-e021-7e432329d439"
   },
   "outputs": [],
   "source": [
    "# Remove comma from population\n",
    "df['Job City Population'] = df['Job City Population'].str.replace(',', '')\n",
    "\n",
    "# Convert the City population and Company size to integer format\n",
    "df['Job City Population'] = df['Job City Population'].astype('int64')\n",
    "df['Company Size'] = df['Company Size'].astype('int64')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7z647zKBOag",
    "outputId": "3e8b7c74-1b18-41cc-d875-e6fa80351211"
   },
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtXOi-uCcHlR"
   },
   "source": [
    "Reorder Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "jmh8Jwy-KoGC",
    "outputId": "1c4537ba-6b62-40d4-f84f-0ee2fd5dc814"
   },
   "outputs": [],
   "source": [
    "# Reorder columns based on the desired order\n",
    "desired_order = ['Job Id','Minimum Experience (years)',\n",
    "                 'Maximum Experience (years)','Qualifications',\n",
    "                 'Minimum Salary', 'Maximum Salary', 'City', 'Country', 'Job City Population',\n",
    "                 'Work Type', 'Day', 'Month', 'Year', 'Quarter', 'Gender Preference', 'Job Title', 'Specialization',\n",
    "                 'Job Portal', 'Skills', 'Responsibilities', 'Company', 'Company Size', 'Company Sector',\n",
    "                 'Company Industry', 'Company HQ City', 'Company HQ Country', 'Company Ticker',\n",
    "                 'Retirement Plans', 'Stock Options or Equity Grants', 'Parental Leave','Paid Time Off (PTO)',\n",
    "                 'Flexible Work Arrangements','Health Insurance', 'Life and Disability Insurance',\n",
    "                 'Employee Assistance Program','Health and Wellness Facilities','Employee Referral Program',\n",
    "                 'Transportation Benefits','Bonuses and Incentive Programs']\n",
    "\n",
    "df = df[desired_order]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8djD_Fqs7-fi"
   },
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CwLHtm8d0zU"
   },
   "source": [
    "### Surrogate Key Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ne9Cz_88eEHQ"
   },
   "outputs": [],
   "source": [
    "# Create a new column new_result with sequential indices for each row\n",
    "df['Surrogate Keys'] = range(1,len(df)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbljQlGnePl4"
   },
   "outputs": [],
   "source": [
    "# after generation, surrogate key column is at the end of the dataset\n",
    "# this code brings it to the beginning\n",
    "df = df.reindex(columns=['Surrogate Keys'] + list([c for c in df.columns if c!= 'Surrogate Keys']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "8fDr35WZeTaT",
    "outputId": "67f5c868-71ad-472d-88a8-bb2ef19b9d29"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLnBrpPVewrE"
   },
   "source": [
    "### Saving the fully staged data for loading into a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FbUKPHaezXo"
   },
   "outputs": [],
   "source": [
    " # convert it back to csv\n",
    "df.to_csv('Staged_data.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
